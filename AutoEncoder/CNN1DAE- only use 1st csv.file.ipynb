{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from keras.layers import Input, Conv1D, Conv2D, Conv2DTranspose\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import normalize\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0049</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>549.68</td>\n",
       "      <td>1343.43</td>\n",
       "      <td>1112.93</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.99</td>\n",
       "      <td>8074.83</td>\n",
       "      <td>9.3335</td>\n",
       "      <td>0.02</td>\n",
       "      <td>330</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.62</td>\n",
       "      <td>6.3670</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20.0020</td>\n",
       "      <td>0.7002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>491.19</td>\n",
       "      <td>606.07</td>\n",
       "      <td>1477.61</td>\n",
       "      <td>1237.50</td>\n",
       "      <td>9.35</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.73</td>\n",
       "      <td>8046.13</td>\n",
       "      <td>9.1913</td>\n",
       "      <td>0.02</td>\n",
       "      <td>361</td>\n",
       "      <td>2324</td>\n",
       "      <td>100.00</td>\n",
       "      <td>24.37</td>\n",
       "      <td>14.6552</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0038</td>\n",
       "      <td>0.8409</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.95</td>\n",
       "      <td>1343.12</td>\n",
       "      <td>1117.05</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2387.97</td>\n",
       "      <td>8066.62</td>\n",
       "      <td>9.4007</td>\n",
       "      <td>0.02</td>\n",
       "      <td>329</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.48</td>\n",
       "      <td>6.4213</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42.0000</td>\n",
       "      <td>0.8400</td>\n",
       "      <td>100.0</td>\n",
       "      <td>445.00</td>\n",
       "      <td>548.70</td>\n",
       "      <td>1341.24</td>\n",
       "      <td>1118.03</td>\n",
       "      <td>3.91</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8076.05</td>\n",
       "      <td>9.3369</td>\n",
       "      <td>0.02</td>\n",
       "      <td>328</td>\n",
       "      <td>2212</td>\n",
       "      <td>100.00</td>\n",
       "      <td>10.54</td>\n",
       "      <td>6.4176</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>25.0063</td>\n",
       "      <td>0.6207</td>\n",
       "      <td>60.0</td>\n",
       "      <td>462.54</td>\n",
       "      <td>536.10</td>\n",
       "      <td>1255.23</td>\n",
       "      <td>1033.59</td>\n",
       "      <td>7.05</td>\n",
       "      <td>...</td>\n",
       "      <td>2028.08</td>\n",
       "      <td>7865.80</td>\n",
       "      <td>10.8366</td>\n",
       "      <td>0.02</td>\n",
       "      <td>305</td>\n",
       "      <td>1915</td>\n",
       "      <td>84.93</td>\n",
       "      <td>14.03</td>\n",
       "      <td>8.6754</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1        2       3      4       5       6        7        8     9  ...  \\\n",
       "0  1  1  42.0049  0.8400  100.0  445.00  549.68  1343.43  1112.93  3.91  ...   \n",
       "1  1  2  20.0020  0.7002  100.0  491.19  606.07  1477.61  1237.50  9.35  ...   \n",
       "2  1  3  42.0038  0.8409  100.0  445.00  548.95  1343.12  1117.05  3.91  ...   \n",
       "3  1  4  42.0000  0.8400  100.0  445.00  548.70  1341.24  1118.03  3.91  ...   \n",
       "4  1  5  25.0063  0.6207   60.0  462.54  536.10  1255.23  1033.59  7.05  ...   \n",
       "\n",
       "        17       18       19    20   21    22      23     24       25  label  \n",
       "0  2387.99  8074.83   9.3335  0.02  330  2212  100.00  10.62   6.3670      0  \n",
       "1  2387.73  8046.13   9.1913  0.02  361  2324  100.00  24.37  14.6552      0  \n",
       "2  2387.97  8066.62   9.4007  0.02  329  2212  100.00  10.48   6.4213      0  \n",
       "3  2388.02  8076.05   9.3369  0.02  328  2212  100.00  10.54   6.4176      0  \n",
       "4  2028.08  7865.80  10.8366  0.02  305  1915   84.93  14.03   8.6754      0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################################\n",
    "# train 데이터 load\n",
    "####################################\n",
    "# train set load\n",
    "train_dataset = pd.read_csv('C:/Users/ARA/Desktop/금형/python/data/train_failure30_4.csv', header=0)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique columns 추출\n",
    "uniq_col = []\n",
    "for i in range(train_dataset.shape[1]):\n",
    "    if len(np.unique(train_dataset.iloc[:,i], axis=0)) != 1: uniq_col.append(i)\n",
    "uniq_col.remove(0)\n",
    "uniq_col.remove(1)\n",
    "uniq_col.remove(26)\n",
    "len(uniq_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.T.reset_index(drop=True).T\n",
    "train_dataset.rename(columns={0:'id', 1:'cycle', 26:'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# NASA_Preparation에서 패딩 사용 안했을 때\\n\\n# 150보다 작은 정상 데이터만 학습용으로 추출\\ntrain_dataset2 = train_dataset[train_dataset['cycle']< 150]\\ntrain_dataset3 = train_dataset2[train_dataset2['label']!=1]\\ntrain_dataset3 = train_dataset3[train_dataset3['label']!=2]\\ntrain_uniq = np.asarray(train_dataset3[uniq_col])\\n\\n# scaling\\nsc = StandardScaler()\\ntrain_uniq = sc.fit_transform(train_uniq)\\n\\n\\nX_train = np.reshape(train_uniq, (train_uniq.shape[0], train_uniq.shape[1], 1, 1))\\nX_train.shape\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# NASA_Preparation에서 패딩 사용 안했을 때\n",
    "\n",
    "# 150보다 작은 정상 데이터만 학습용으로 추출\n",
    "train_dataset2 = train_dataset[train_dataset['cycle']< 150]\n",
    "train_dataset3 = train_dataset2[train_dataset2['label']!=1]\n",
    "train_dataset3 = train_dataset3[train_dataset3['label']!=2]\n",
    "train_uniq = np.asarray(train_dataset3[uniq_col])\n",
    "\n",
    "# scaling\n",
    "sc = StandardScaler()\n",
    "train_uniq = sc.fit_transform(train_uniq)\n",
    "\n",
    "\n",
    "X_train = np.reshape(train_uniq, (train_uniq.shape[0], train_uniq.shape[1], 1, 1))\n",
    "X_train.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정상 데이터 shape:  (42688, 27)\n",
      "훈련에 사용할 데이터 shape:  (42688, 24, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# NASA_Preparation 에서 정상만 훈련시키고 싶을때 (또는 이미 패딩 사용했을 시), 이 부분 적용\n",
    "\n",
    "# 정상 데이터만 학습\n",
    "train_seq_T = train_dataset[train_dataset['label']==0]\n",
    "print(\"정상 데이터 shape: \", train_seq_T.shape)\n",
    "\n",
    "# scaling\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train = np.asarray(train_seq_T[uniq_col])\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1, 1))\n",
    "\n",
    "print(\"훈련에 사용할 데이터 shape: \", X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n####################################\\n# Model\\n####################################\\ninput_data = Input(shape=X_train.shape[1:])\\n\\nx = Conv1D(8, activation='relu', kernel_size=3, padding='same')(input_data)\\nx = Conv1D(8, activation='relu', kernel_size=3, padding='same')(x)\\nencoded = Conv1D(2, activation='relu', kernel_size=3, padding='same')(x)\\n\\nx = Conv1D(4, activation='relu', kernel_size=3, padding='same')(encoded)\\nx = Conv1D(8, activation='relu', kernel_size=3, padding='same')(x)\\nx = Conv1D(8, activation='relu', kernel_size=3, padding='same')(x)\\ndecoded = Conv1D(1, activation='sigmoid', kernel_size=3, padding='same')(x)\\n\\nautoencoder = Model(input_data, decoded)\\nencoder = Model(input_data, encoded)\\n\\nautoencoder.compile(loss='mse', optimizer='adadelta', metrics=['acc'])\\nencoder.compile(loss='mse', optimizer='adadelta', metrics=['acc'])\\n\\nautoencoder.summary()\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "####################################\n",
    "# Model\n",
    "####################################\n",
    "input_data = Input(shape=X_train.shape[1:])\n",
    "\n",
    "x = Conv1D(8, activation='relu', kernel_size=3, padding='same')(input_data)\n",
    "x = Conv1D(8, activation='relu', kernel_size=3, padding='same')(x)\n",
    "encoded = Conv1D(2, activation='relu', kernel_size=3, padding='same')(x)\n",
    "\n",
    "x = Conv1D(4, activation='relu', kernel_size=3, padding='same')(encoded)\n",
    "x = Conv1D(8, activation='relu', kernel_size=3, padding='same')(x)\n",
    "x = Conv1D(8, activation='relu', kernel_size=3, padding='same')(x)\n",
    "decoded = Conv1D(1, activation='sigmoid', kernel_size=3, padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_data, decoded)\n",
    "encoder = Model(input_data, encoded)\n",
    "\n",
    "autoencoder.compile(loss='mse', optimizer='adadelta', metrics=['acc'])\n",
    "encoder.compile(loss='mse', optimizer='adadelta', metrics=['acc'])\n",
    "\n",
    "autoencoder.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 24, 1, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 20, 1, 4)          24        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 1, 4)          84        \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 1, 8)          168       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 1, 16)          656       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 12, 1, 8)          648       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 16, 1, 4)          164       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 20, 1, 4)          84        \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 24, 1, 1)          21        \n",
      "=================================================================\n",
      "Total params: 1,849\n",
      "Trainable params: 1,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#######################################\n",
    "# CNN1D AutoEncoder 구축\n",
    "#######################################\n",
    "\n",
    "input_data = Input(shape=X_train.shape[1:]) # 1ch=black&white\n",
    "\n",
    "#@@ C-AE 구현http://localhost:8888/notebooks/Desktop/%EA%B8%88%ED%98%95/python/AutoEncoder/CNN1DAE.ipynb#\n",
    "filter1 = 4\n",
    "filter2 = 4\n",
    "filter3 = 8\n",
    "kernel_size1 = 5\n",
    "kernel_size2 = 5\n",
    "\n",
    "x = Conv2D(filter1, kernel_size= (kernel_size1,1), activation='relu')(input_data)\n",
    "x = Conv2D(filter2, kernel_size= (kernel_size1,1), activation='relu')(x)\n",
    "x = Conv2D(filter3, kernel_size= (kernel_size1,1), activation='relu')(x)\n",
    "encoded = Conv2D(16, kernel_size= (kernel_size2,1), activation='sigmoid')(x)\n",
    "\n",
    "x = Conv2DTranspose(filter3, kernel_size= (kernel_size2,1), activation='relu')(encoded)\n",
    "x = Conv2DTranspose(filter2, kernel_size= (kernel_size1,1), activation='relu')(x)\n",
    "x = Conv2DTranspose(filter1, kernel_size= (kernel_size1,1), activation='relu')(x)\n",
    "decoded = Conv2DTranspose(X_train.shape[-1], kernel_size=(kernel_size1,1), activation='sigmoid')(x)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.01)\n",
    "autoencoder = Model(input_data, decoded)\n",
    "autoencoder.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40553 samples, validate on 2135 samples\n",
      "Epoch 1/100\n",
      "40553/40553 [==============================] - 2s 48us/step - loss: 1.0372 - val_loss: 0.9432\n",
      "Epoch 2/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.8240 - val_loss: 0.7741\n",
      "Epoch 3/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.7085 - val_loss: 0.6909\n",
      "Epoch 4/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6846 - val_loss: 0.6806\n",
      "Epoch 5/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6778 - val_loss: 0.6750\n",
      "Epoch 6/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6665 - val_loss: 0.6623\n",
      "Epoch 7/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6601 - val_loss: 0.6588\n",
      "Epoch 8/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6578 - val_loss: 0.6573\n",
      "Epoch 9/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6567 - val_loss: 0.6563\n",
      "Epoch 10/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6558 - val_loss: 0.6555\n",
      "Epoch 11/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6556 - val_loss: 0.6555\n",
      "Epoch 12/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6547 - val_loss: 0.6542\n",
      "Epoch 13/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6539 - val_loss: 0.6536\n",
      "Epoch 14/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6535 - val_loss: 0.6534\n",
      "Epoch 15/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6532 - val_loss: 0.6532\n",
      "Epoch 16/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6532 - val_loss: 0.6537\n",
      "Epoch 17/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6530 - val_loss: 0.6527\n",
      "Epoch 18/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6525 - val_loss: 0.6523\n",
      "Epoch 19/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6569 - val_loss: 0.6580\n",
      "Epoch 20/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6544 - val_loss: 0.6527\n",
      "Epoch 21/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6523 - val_loss: 0.6520\n",
      "Epoch 22/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6519 - val_loss: 0.6518\n",
      "Epoch 23/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6518 - val_loss: 0.6515\n",
      "Epoch 24/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6513 - val_loss: 0.6506\n",
      "Epoch 25/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6505 - val_loss: 0.6502\n",
      "Epoch 26/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6502 - val_loss: 0.6500\n",
      "Epoch 27/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6514 - val_loss: 0.6503\n",
      "Epoch 28/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6501 - val_loss: 0.6499\n",
      "Epoch 29/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6499 - val_loss: 0.6498\n",
      "Epoch 30/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6499 - val_loss: 0.6496\n",
      "Epoch 31/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6497 - val_loss: 0.6496\n",
      "Epoch 32/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6499 - val_loss: 0.6497\n",
      "Epoch 33/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6497 - val_loss: 0.6494\n",
      "Epoch 34/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6495 - val_loss: 0.6494\n",
      "Epoch 35/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6495 - val_loss: 0.6493\n",
      "Epoch 36/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6494 - val_loss: 0.6492\n",
      "Epoch 37/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6497 - val_loss: 0.6509\n",
      "Epoch 38/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6497 - val_loss: 0.6492\n",
      "Epoch 39/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6493 - val_loss: 0.6491\n",
      "Epoch 40/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6492 - val_loss: 0.6491\n",
      "Epoch 41/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6493 - val_loss: 0.6492\n",
      "Epoch 42/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6493 - val_loss: 0.6490\n",
      "Epoch 43/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6491 - val_loss: 0.6490\n",
      "Epoch 44/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6491 - val_loss: 0.6490\n",
      "Epoch 45/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6491 - val_loss: 0.6489\n",
      "Epoch 46/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6490 - val_loss: 0.6489\n",
      "Epoch 47/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6490 - val_loss: 0.6489\n",
      "Epoch 48/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6490 - val_loss: 0.6489\n",
      "Epoch 49/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6490 - val_loss: 0.6489\n",
      "Epoch 50/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6490 - val_loss: 0.6489\n",
      "Epoch 51/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6490 - val_loss: 0.6489\n",
      "Epoch 52/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6490 - val_loss: 0.6489\n",
      "Epoch 53/100\n",
      "40553/40553 [==============================] - 1s 34us/step - loss: 0.6490 - val_loss: 0.6488\n",
      "Epoch 54/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6490 - val_loss: 0.6488\n",
      "Epoch 55/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6489 - val_loss: 0.6490\n",
      "Epoch 56/100\n",
      "40553/40553 [==============================] - 1s 33us/step - loss: 0.6490 - val_loss: 0.6488\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2d7b5b4ed68>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(patience=3, mode='min')\n",
    "autoencoder.fit(X_train, X_train, epochs= 100, batch_size=1024, shuffle=True, verbose=1, validation_split=0.05, callbacks=[early_stopping]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48658, 24)\n",
      "(48658, 24, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# all_data: 정상 + 이상인 전체 훈련 데이터 셋\n",
    "all_data = np.asarray(train_dataset[uniq_col])\n",
    "\n",
    "# scaling\n",
    "all_data = sc.transform(all_data)\n",
    "print(all_data.shape)\n",
    "all_data = np.reshape(all_data, (all_data.shape[0], all_data.shape[1], 1, 1))\n",
    "print(all_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### 인코더에서 특성 추출 for 2D plotting\\nencoder = Model(input_data, encoded)\\nencoder.compile(optimizer=\\'adam\\', loss=\\'mse\\')\\n\\nenco_train_pred = encoder.predict(all_data)\\nprint(\"enco_train_pred.shape: \", enco_train_pred.shape)\\n\\nenco_train_re = np.reshape(enco_train_pred,(len(enco_train_pred),2))\\nprint(\"enco_train_re.shape: \", enco_train_re.shape)\\n\\nlabel = np.asarray(train_dataset[\\'label\\'])\\nlabel = label.reshape((len(label),1))\\nprint(\"label.shape: \",label.shape)\\nprint(\"np.sum(label): \", np.sum(label))\\n\\nX_reduce = pd.DataFrame()\\nX_reduce[\\'x\\'] = [enco_train_re[x][0] for x in range(0,len(enco_train_re))]\\nX_reduce[\\'y\\'] = [enco_train_re[x][1] for x in range(0,len(enco_train_re))]\\nX_reduce[\\'label\\'] = label\\n\\nb1 = plt.scatter(X_reduce[\\'x\\'][X_reduce.label == 1], X_reduce[\\'y\\'][X_reduce.label == 1], c= \\'red\\', s= 20, alpha= 0.5)\\nb1 = plt.scatter(X_reduce[\\'x\\'][X_reduce.label == 0], X_reduce[\\'y\\'][X_reduce.label == 0], c= \\'yellow\\', s= 20, alpha= 0.05)\\n\\nplt.show()\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "### 인코더에서 특성 추출 for 2D plotting\n",
    "encoder = Model(input_data, encoded)\n",
    "encoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "enco_train_pred = encoder.predict(all_data)\n",
    "print(\"enco_train_pred.shape: \", enco_train_pred.shape)\n",
    "\n",
    "enco_train_re = np.reshape(enco_train_pred,(len(enco_train_pred),2))\n",
    "print(\"enco_train_re.shape: \", enco_train_re.shape)\n",
    "\n",
    "label = np.asarray(train_dataset['label'])\n",
    "label = label.reshape((len(label),1))\n",
    "print(\"label.shape: \",label.shape)\n",
    "print(\"np.sum(label): \", np.sum(label))\n",
    "\n",
    "X_reduce = pd.DataFrame()\n",
    "X_reduce['x'] = [enco_train_re[x][0] for x in range(0,len(enco_train_re))]\n",
    "X_reduce['y'] = [enco_train_re[x][1] for x in range(0,len(enco_train_re))]\n",
    "X_reduce['label'] = label\n",
    "\n",
    "b1 = plt.scatter(X_reduce['x'][X_reduce.label == 1], X_reduce['y'][X_reduce.label == 1], c= 'red', s= 20, alpha= 0.5)\n",
    "b1 = plt.scatter(X_reduce['x'][X_reduce.label == 0], X_reduce['y'][X_reduce.label == 0], c= 'yellow', s= 20, alpha= 0.05)\n",
    "\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48658, 24, 1, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##############################################\n",
    "### CNN_AE predict - train data로 다시\n",
    "##############################################\n",
    "cnn1d_predict = autoencoder.predict(all_data)\n",
    "cnn1d_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48658, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE 계산을 위한 flattening\n",
    "cnn1d_predict = cnn1d_predict.reshape(cnn1d_predict.shape[0], cnn1d_predict.shape[1]* cnn1d_predict.shape[2])\n",
    "cnn1d_predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48658, 24)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = all_data.reshape(all_data.shape[0], all_data.shape[1]* all_data.shape[2])\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse.shape:  (48658,)\n",
      "최소값:  0.14485920646234732 \n",
      "중간값:  0.6466793030166308 \n",
      "최대값:  2.3970526747360297\n"
     ]
    }
   ],
   "source": [
    "### calculate MSE\n",
    "mse = mean_squared_error(all_data.T, cnn1d_predict.T, multioutput='raw_values')\n",
    "print(\"mse.shape: \", mse.shape)\n",
    "\n",
    "print(\"최소값: \", np.min(mse), \"\\n중간값: \",np.mean(mse), \"\\n최대값: \", np.max(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정상 데이터 수:  42642\n",
      "예측 고장 데이터 수:  6016\n",
      "전체 데이터 수:  (48658, 1)\n",
      "실제 고장 데이터 수:  5970\n"
     ]
    }
   ],
   "source": [
    "### labeling\n",
    "# mse < border\n",
    "border = 2.22\n",
    "label= [0 if  mse[x] < border else 1 for x in range(0,len(mse)) ]    # 정상 0, 이상 2\n",
    "X_reduce = pd.DataFrame()\n",
    "X_reduce['label'] = label\n",
    "idx_0 = X_reduce[X_reduce.label == 0].index\n",
    "idx_2 = X_reduce[X_reduce.label == 1].index\n",
    "print(\"예측 정상 데이터 수: \",len(idx_0))\n",
    "print(\"예측 고장 데이터 수: \",len(idx_2))\n",
    "\n",
    "label = np.asarray(train_dataset['label'])\n",
    "label = label.reshape((len(label),1))\n",
    "print(\"전체 데이터 수: \",label.shape)\n",
    "print(\"실제 고장 데이터 수: \", len(label[label==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d7bbe8b898>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(label, X_reduce['label']))\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7646430186197543"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_cm.iloc[0,0]+df_cm.iloc[1,1])/(np.sum(df_cm)[0]+np.sum(df_cm)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.87      0.87     42688\n",
      "         1.0       0.04      0.04      0.04      5970\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     48658\n",
      "   macro avg       0.46      0.46      0.46     48658\n",
      "weighted avg       0.77      0.76      0.77     48658\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(label, X_reduce['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12591, 24)\n",
      "(12591, 24, 1, 1)\n",
      "cnn1d_test_predict.shape:  (12591, 24)\n"
     ]
    }
   ],
   "source": [
    "##############################################\n",
    "### CNN_AE predict - test data\n",
    "##############################################\n",
    "# test set load\n",
    "test_dataset = pd.read_csv('C:/Users/ARA/Desktop/금형/python/data/test_failure30_4.csv', header=0)\n",
    "test_dataset = test_dataset.T.reset_index(drop=True).T\n",
    "test_dataset.rename(columns={0:'id', 1:'cycle', 26:'label'}, inplace=True)\n",
    "\n",
    "# scaling\n",
    "test_dataset[uniq_col] = sc.transform(test_dataset[uniq_col])\n",
    "\n",
    "all_test_data = np.asarray(test_dataset[uniq_col])\n",
    "print(all_test_data.shape)\n",
    "all_test_data = np.reshape(all_test_data, (all_test_data.shape[0], all_data.shape[1], 1, 1))\n",
    "print(all_test_data.shape)\n",
    "\n",
    "cnn1d_test_predict = autoencoder.predict(all_test_data)\n",
    "\n",
    "# MSE 계산을 위한 flattening\n",
    "cnn1d_test_predict = cnn1d_test_predict.reshape(cnn1d_test_predict.shape[0], cnn1d_test_predict.shape[1]* cnn1d_test_predict.shape[2])\n",
    "print(\"cnn1d_test_predict.shape: \", cnn1d_test_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_test_data.shape:  (12591, 24)\n"
     ]
    }
   ],
   "source": [
    "all_test_data = all_test_data.reshape(all_test_data.shape[0], all_test_data.shape[1]* all_test_data.shape[2])\n",
    "print(\"all_test_data.shape: \", all_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse_test.shape:  (12591,)\n",
      "최소값:  0.14551294102954207 중간값:  0.655600989782618 최대값:  2.3741159594721606\n"
     ]
    }
   ],
   "source": [
    "### calculate MSE\n",
    "mse_test = mean_squared_error(all_test_data.T, cnn1d_test_predict.T, multioutput='raw_values')\n",
    "print(\"mse_test.shape: \", mse_test.shape)\n",
    "\n",
    "print(\"최소값: \", np.min(mse_test), \"중간값: \",np.mean(mse_test), \"최대값: \", np.max(mse_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정상 데이터 수:  10980\n",
      "예측 고장 데이터 수:  1611\n",
      "\n",
      "전체 데이터 수:  12591\n",
      "실제 고장 데이터 수:  1500\n"
     ]
    }
   ],
   "source": [
    "### labeling\n",
    "# mse < border\n",
    "border = 2.22\n",
    "label= [0 if  mse_test[x] < border else 1 for x in range(0,len(mse_test)) ]    # 정상 0, 이상 2\n",
    "X_reduce_test = pd.DataFrame()\n",
    "X_reduce_test['label'] = label\n",
    "idx_0 = X_reduce_test[X_reduce_test.label == 0].index\n",
    "idx_2 = X_reduce_test[X_reduce_test.label == 1].index\n",
    "print(\"예측 정상 데이터 수: \",len(idx_0))\n",
    "print(\"예측 고장 데이터 수: \",len(idx_2))\n",
    "\n",
    "test_label = np.asarray(test_dataset['label'])\n",
    "label = test_label.reshape((len(test_label),1))\n",
    "print(\"\\n전체 데이터 수: \",label.shape[0])\n",
    "print(\"실제 고장 데이터 수: \", len(label[label==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2d7bbe5ec18>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGfCAYAAAB8wYmvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAHA5JREFUeJzt3Xu4XVV5L+DfSDZXL4EARgjIRaiIp6JWEdEjcpGLVEEKR9QKIm3EYtV6RVBpARWPCmqL1mhABA4RQUqwXIpcRK0gFBEFpEmBQki4JoBUAcke549M0o3s7MS6kzVn5vv6rCdrjTnnnmP7PDGfv2+MuUqtNQAAbTZh0BMAAFgWBQsA0HoKFgCg9RQsAEDrKVgAgNZTsAAAradgAQBaT8ECALSeggUAaL2hFX2D3953i0fpwgDsvO1fDnoK0Fs/uPOSsjLvN57/1q62/hYrde7LS8ICALTeCk9YAIAVbHjRoGewwklYAIDWk7AAQNfV4UHPYIVTsABA1w2v+gWLlhAA0HoSFgDouKolBAC0npYQAMDgSVgAoOu0hACA1vPgOACAwZOwAEDXaQkBAK1nlxAAwOBJWACg4zw4DgBoPy0hAIDBk7AAQNdpCQEArefBcQAAgydhAYCu0xICAFrPLiEAgMGTsABA12kJAQCtpyUEADB4EhYA6LhaV/3nsChYAKDrerCGRUsIAGg9CQsAdF0PFt0qWACg63rQElKwAEDX+fJDAIDBk7AAQNdpCQEArdeDRbdaQgBA60lYAKDrtIQAgNbTEgIAGDwJCwB0XQ8SFgULAHRcH76tWUsIAGg9CQsAdJ2WEADQej3Y1qwlBAC0noQFALpOSwgAaD0tIQCAwZOwAEDXaQkBAK2nJQQAMHgSFgDoOi0hAKD1elCwaAkBAK0nYQGAruvBolsFCwB0nZYQAMB/K6X8TSnlhlLKL0opZ5RS1iylbF5KuaqUMruU8q1SyurNuWs0n+c0xzcb8XM+2ozfXErZfVn3VbAAQNfV4fF7jaGUMjXJe5K8tNb6v5JMTHJAks8kOaHWulWShUkOaS45JMnCWuuWSU5ozkspZZvmuhck2SPJl0spE8e6t4IFALpueHj8Xss2lGStUspQkrWTzE+yc5KzmuOnJNmneb938znN8V1KKaUZn1lrfbTWemuSOUm2G+umChYAYLnUWu9M8rkkt2dxofJgkn9L8kCt9fHmtLlJpjbvpya5o7n28eb89UaOj3LNqBQsANB149gSKqVMK6VcM+I17YnblFLWzeJ0ZPMkGyV5WpI9R5vRE5cs5djSxpfKLiEA6Lpx3CVUa52eZPpSDu+a5NZa671JUkr5TpIdkqxTShlqUpSNk8xrzp+bZJMkc5sW0qQkC0aMP2HkNaOSsAAAy+v2JNuXUtZu1qLskuTGJJcl2a8556Ak5zbvZzWf0xy/tNZam/EDml1EmyfZKslPxrqxhAUAum4lPYel1npVKeWsJNcmeTzJT7M4jfnnJDNLKcc2YzOaS2YkObWUMieLk5UDmp9zQynlzCwudh5PclitddFY91awAEDX1TGXf4zzrepRSY76neFbMsoun1rrI0n2X8rP+WSSTy7vfbWEAIDWk7AAQNf14NH8ChYA6LoeFCxaQgBA60lYAKDrlvEdQKsCBQsAdJ2WEADA4ElYAKDrVuJzWAZFwQIAXaclBAAweBIWAOi6HiQsChYA6LoebGvWEgIAWk/CAgAdV4ftEgIA2q4Ha1i0hACA1pOwAEDX9WDRrYIFALquB2tYtIQAgNaTsABA1/Vg0a2CBQC6TsECALReD76t2RoWAKD1JCwA0HVaQqyKTj3zn3L2rAtTa81+b9gjb3vTG3PijNNy9qwLs+46k5Ik733nQXn1Dtvl5zfenL/9zJeSJDU1f/WOt2bXHV+ZJPnmzHNy9nkXppSSrZ67WY494v1ZY43VB/Z7QZsd/vkPZoddt8/C+x7IQbv8RZLk4PcfmNe/Za88sOCBJMn042bkykt/kmdvPCWnXX5ybr/ljiTJDdfelM8f/oUkyedO+3TWm7JeJk6cmJ/95Oc54YgvZbgH/1ixDD3Y1qxg6ZnZt9yWs2ddmDO+/oWsNrRaDv3Ax/LqHbZLkrztTfvk4Lfs96Tzt9xi03xrxpcyNDQx9963IH920F/lNa/cPvcvXJjTzzo3557+1ay5xhr5wMc/lQu+9/3ss9drB/FrQetdcOZF+c7J5+bIL37kSeNnfu2szPzqt59y/p3/OS/v2O2dTxn/xKHH5NcP/zpJcsz0o7LTn+6YS2ZdtmImDS2yzIKllLJ1kr2TTE1Sk8xLMqvWetMKnhsrwC233ZEXvmDrrLXmmkmSl77oj3PJFf+61POfOC9JHn3ssaSUJZ8fX7Qojz76WIYmDuU3jzyaDdafvOImDh33s6t+nmdvPOUP/jlPFCsThyZmtdVXS82q//+sWQ49eNLtmItuSykfSTIzSUnykyRXN+/PKKUcvuKnx3jbcotN828/+0UeePCh/OaRR/KDH1+du+6+N0lyxtnn5Y0Hvisf+9TxefChXy255vobfpm93/rOvPHAd+UTH3p3hoYmZsoG6+ftb/6z7Lrvgdlp77fkGU9bO698+Z8M6teCztr34H3yjYu/lsM//8E8fdLTl4xv+JxnZ8ZF/5i/P+v4vHC7P37SNZ8//bic97Oz8+uHf53Lv3vFyp4ybTRcx+/VUsvaJXRIkpfVWo+rtZ7WvI5Lsl1zbFSllGmllGtKKdd8/ZtnjOd8+QM9d7Pn5B1v3T9/+b4jcuj7P54/2nKLTJw4MW9641654MyTcvY3TswG603OZ//ha0uueeELts65p381M7/+xXz91DPz6KOP5cGHfpXLfnBlLvr2ybn03NPzm0cezXkXXTrA3wy655++eV4O2OFtOXi3abn/ngV59ycOTZLcf8+C7LfdW3LI7ofm7//uK/nEiUdk7aevveS6D7z18Ozzkv2z2uqr5SWvfPGgpg8r1bIKluEkG40yvmFzbFS11um11pfWWl/6Fwe++Q+ZHyvAn71+93z75H/IKV/+bCY98xnZdJOpWX/yupk4cWImTJiQ/d6wZ35x478/5brnbvacrLXmmpl9y2258prrMnWjKZm87jpZbWgou+y4Q677+Y0D+G2guxbetzDDw8Optea80/85z3/R1kmS3z722zy08KEkyb//fHbm3TYvm2yx8ZOufezR3+ZHF/84r9p9h5U+b9qnDg+P26utllWwvC/JJaWUC0op05vXhUkuSfLeFT89VoT7Fy7ekTD/rntyyfd/lD133TH33rdgyfFLvv+v2XKLTZMkc+fdlccfX5QkmXfX3bnt9rmZuuGUbDhlg1z/i1/mN488klprrrrmumyx6SYr/5eBDlvvWf+97uvVe74qt958W5JkncmTMmHC4v953vA5G2bjzTfOvNvnZ62111xyzcSJE7L9ztvl9jm3r/R500I9aAmNuei21nphKeWPsrgFNDWL16/MTXJ1rXXRSpgfK8DfHHFsHnjooQwNDeXID/xVJj3zGTn86M/m5tm3JCWZ+uwpOerD70mSXHv9DZlx6pkZGhrKhAklH/vgYVl3nUlZd51Jee1Or8r/OfivM3HixGz9R8/N/nvvOeDfDNrrqBOPzItfsW0mTZ6Us6+ZmZM+d0pevMO22XKb5yY1mT/3rnzuIyckSbbd/oU55INvz6JFizK8aDif++gX8qsHfpV11183nz75mKy++uqZMHFCrv3RT3PuqecN+DeDlaPUFfw439/ed0t7yzVYhe287V8OegrQWz+485Ky7LPGz38d++fj9m/t0z522kqd+/LyHBYA6LoWt3LGi+8SAgBaT8ICAF3X4t0940XBAgBdpyUEADB4EhYA6LoefJeQggUAuk5LCABg8CQsANBxbf4OoPGiYAGArtMSAgAYPAkLAHRdDxIWBQsAdF0PtjVrCQEArSdhAYCu0xICANqu9qBg0RICAFpPwgIAXdeDhEXBAgBd14Mn3WoJAQCtJ2EBgK7TEgIAWq8HBYuWEADQehIWAOi4Wlf9hEXBAgBdpyUEADB4EhYA6LoeJCwKFgDoON8lBADQAhIWAOi6HiQsChYA6LpV/6uEtIQAgPaTsABAx/Vh0a2CBQC6rgcFi5YQANB6EhYA6LoeLLpVsABAx/VhDYuWEADQehIWAOi6HrSEJCwA0HF1uI7ba1lKKeuUUs4qpfyylHJTKeUVpZTJpZSLSymzmz/Xbc4tpZQvlVLmlFKuL6W8ZMTPOag5f3Yp5aBl3VfBAgD8Pr6Y5MJa69ZJtk1yU5LDk1xSa90qySXN5yTZM8lWzWtakq8kSSllcpKjkrw8yXZJjnqiyFkaBQsAdN3wOL7GUEp5ZpJXJ5mRJLXWx2qtDyTZO8kpzWmnJNmneb93km/Wxa5Msk4pZcMkuye5uNa6oNa6MMnFSfYY694KFgDouDo8fq9SyrRSyjUjXtNG3GqLJPcmObmU8tNSytdLKU9LMqXWOj9Jmj+f1Zw/NckdI66f24wtbXypLLoFgK4bx0W3tdbpSaYv5fBQkpck+eta61WllC/mv9s/oymj3WKM8aWSsAAAy2tukrm11quaz2dlcQFzd9PqSfPnPSPO32TE9RsnmTfG+FIpWACg48azJTTmfWq9K8kdpZTnNUO7JLkxyawkT+z0OSjJuc37WUkObHYLbZ/kwaZldFGS3Uop6zaLbXdrxpZKSwgAum7lPoflr5OcXkpZPcktSQ7O4gDkzFLKIUluT7J/c+75SV6XZE6SXzfnpta6oJRyTJKrm/OOrrUuGOumChYAYLnVWq9L8tJRDu0yyrk1yWFL+TknJTlpee+rYAGAjltWK2dVoGABgI7rQ8Fi0S0A0HoSFgDouD4kLAoWAOi6Otpz2FYtWkIAQOtJWACg47SEAIDWq8NaQgAAAydhAYCO0xICAFqv2iUEADB4EhYA6DgtIQCg9ewSAgBoAQkLAHRcrYOewYqnYAGAjtMSAgBoAQkLAHRcHxIWBQsAdFwf1rBoCQEArSdhAYCO0xICAFrPdwkBALSAhAUAOs53CQEArTesJQQAMHgSFgDouD4sulWwAEDH9WFbs5YQANB6EhYA6Lg+PJpfwQIAHaclBADQAhIWAOi4PjyHRcECAB3Xh23NWkIAQOtJWACg4+wSAgBarw9rWLSEAIDWk7AAQMf1YdGtggUAOq4Pa1i0hACA1lvhCcv/fuE7VvQtgFFcc9/sQU8BWEn6sOhWSwgAOq4Pa1i0hACA1pOwAEDHaQkBAK3Xg01CChYA6Lo+JCzWsAAArSdhAYCO68MuIQULAHTc8KAnsBJoCQEArSdhAYCOq9ESAgBabrgH+5q1hACA1pOwAEDHDWsJAQBt14c1LFpCAEDrSVgAoOP68BwWBQsAdJyWEABAC0hYAKDjtIQAgNbrQ8GiJQQAtJ6EBQA6rg+LbhUsANBxw6t+vaIlBAC0n4QFADrOdwkBAK1XBz2BlUBLCABoPQkLAHSc57AAAK03XMq4vZZHKWViKeWnpZTvNp83L6VcVUqZXUr5Vill9WZ8jebznOb4ZiN+xkeb8ZtLKbsv654KFgDg9/XeJDeN+PyZJCfUWrdKsjDJIc34IUkW1lq3THJCc15KKdskOSDJC5LskeTLpZSJY91QwQIAHVfH8bUspZSNk+yV5OvN55Jk5yRnNaeckmSf5v3ezec0x3dpzt87ycxa66O11luTzEmy3Vj3VbAAQMcNj+NrOXwhyYdHnL5ekgdqrY83n+cmmdq8n5rkjiRpjj/YnL9kfJRrRqVgAQCWKKVMK6VcM+I1bcSxP01yT63130ZeMsqPqcs4NtY1o7JLCAA6bjwfzV9rnZ5k+lIOvzLJG0opr0uyZpJnZnHisk4pZahJUTZOMq85f26STZLMLaUMJZmUZMGI8SeMvGZUEhYA6LjhlHF7jaXW+tFa68a11s2yeNHspbXWtya5LMl+zWkHJTm3eT+r+Zzm+KW11tqMH9DsIto8yVZJfjLWvSUsAMAf6iNJZpZSjk3y0yQzmvEZSU4tpczJ4mTlgCSptd5QSjkzyY1JHk9yWK110Vg3ULAAQMcN4tH8tdbLk1zevL8lo+zyqbU+kmT/pVz/ySSfXN77KVgAoOPGcw1LW1nDAgC0noQFADquD98lpGABgI4bxBqWlU1LCABoPQkLAHRcHxbdKlgAoOP6sIZFSwgAaD0JCwB0XB8SFgULAHRc7cEaFi0hAKD1JCwA0HFaQgBA6/WhYNESAgBaT8ICAB3Xh0fzK1gAoOP68KRbLSEAoPUkLADQcX1YdKtgAYCO60PBoiUEALSehAUAOs4uIQCg9fqwS0jBAgAdZw0LAEALSFgAoOOsYQEAWm+4ByWLlhAA0HoSFgDouD4sulWwAEDHrfoNIS0hAKADJCwA0HFaQgBA6/XhSbdaQgBA60lYAKDj+vAcFgULAHTcql+uaAkBAB0gYQGAjrNLCABovT6sYdESAgBaT8ICAB236ucrChYA6Lw+rGHREgIAWk/CAgAd14dFtwoWAOi4Vb9c0RICADpAwgIAHdeHRbcKFgDouNqDppCWEADQehIWAOg4LSEAoPX6sK1ZSwgAaD0JCwB03KqfryhYAKDztIRY5Rx5/Idz/vXn5PRLT37Ksbcc+qZcOe/yTJo86Unjz9/2efnRHZdkp712TJJs9YIt87VZJ+b/XXZyTvvejOz6hp1WxtRhlTbn36/MT6/9Xq65+l9y5Y/PT5Jsu+0L8qMfnLdk7GUvfdGAZwmDI2HpmX/+1oU56+Rz8okvHvGk8WdttEG2e/WfZP7cu540PmHChBx25Dtz1eVXLxl75DeP5Oj3fip33Hpn1p+yXr5x4fRcefnVefihh1fK7wCrql1fu3/uv3/hks/HferIHHPs8bnwosuy5x4757hPH5ldXrv/AGdIW/Vhl5CEpWeuu+r6PLTwV08Zf9/fvjv/cOxXn9II3f8d++ay86/IwvseWDJ2xy1zc8etdyZJ7rv7/iy8b2HWXe/JqQzwh6u15hnPfEaS5JmTnpF58+8e8IxoqzqO/2mr/3HBUko5eDwnwuD87912yL133Zs5N/7Hk8Y3ePb62XHPV+Wcb85a6rXbvGjrrLb6apl727wVPU1YpdVac8H5Z+SqKy/IXxzy1iTJ+z94VD7z6Y/l1v+4Ov/3uI/nyI99esCzhMH5Q1pCf5fkqQsh6JQ11lojb3/Pn+c9b/7QU4697+/enRM/OT3Dw6OHjes9a3KO+vsjcvR7j0ut7a3KoQte/Zp9Mn/+3dlgg/Vy4QUzc/PNc7LvvnvlAx/625xzzvnZb7/X52tf/Xx23/OAQU+VFupDS2jMgqWUcv3SDiWZMsZ105JMS5LNJ22VZ6290f94gqxYG2+6UTZ8zoY57XszkiQbbLhBTrloet7xunfl+ds+L8d+5RNJkkmTJ+UVu7w8ixYtyhUX/jBrP33tHH/qcfnqZ2bkhmtvHOSvAKuE+U27595778+5516Ql73sRTnwbfvnb96/+O/gWWedl+n/+NlBTpEWa3MrZ7wsK2GZkmT3JAt/Z7wk+delXVRrnZ5kepJsv9FrVv3/FjvsP355a173wjcu+XzOVTPz9j3fmQcXPJh9t3/zkvGPn3B4fvi9H+eKC3+YodWG8pkZx+T8b/9LLv3u9wcxbVilrL32WpkwYUIefvi/svbaa+W1u+6YYz95QubNvzs7vvoV+f4VP87OO70qs+fcOuipwsAsq2D5bpKn11qv+90DpZTLV8iMWKGO/vLH85JXvCjrTJ6UWdd8O1/7/Mk574zzf6+fsevrd8qLt982kyZPyl5v2iNJcsz7jsvsG+asiCnDKm/KlA1y1rcXp5xDQxMzc+Y/5aJ/uTwPH/qhHH/80RkaGsqjjzySd73rwwOeKW3Vh5ZQWdFrDyQsMBjX3Dd70FOA3nr8sTvLyrzf2zbdd9z+rT31P7+zUue+vGxrBgBaz4PjAKDj+tDKULAAQMf5LiEAgBaQsABAx3kOCwDQen3Y1qwlBAC0noQFADquD4tuFSwA0HF9WMOiJQQALJdSyiallMtKKTeVUm4opby3GZ9cSrm4lDK7+XPdZryUUr5USplTSrm+lPKSET/roOb82aWUg5Z1bwULAHTc8Di+luHxJB+otT4/yfZJDiulbJPk8CSX1Fq3SnJJ8zlJ9kyyVfOaluQryeICJ8lRSV6eZLskRz1R5CyNggUAOq7WOm6vZdxnfq312ub9r5LclGRqkr2TnNKcdkqSfZr3eyf5Zl3syiTrlFI2TLJ7kotrrQtqrQuTXJxkj7HurWABAH5vpZTNkrw4yVVJptRa5yeLi5okz2pOm5rkjhGXzW3Glja+VBbdAkDHjecuoVLKtCxu3zxheq11+u+c8/QkZyd5X631oVKW+gXPox2oY4wvlYIFADpuPB8c1xQn05d2vJSyWhYXK6fXWr/TDN9dStmw1jq/afnc04zPTbLJiMs3TjKvGX/N74xfPta8tIQAoOPqOP5nLGVxlDIjyU211uNHHJqV5ImdPgclOXfE+IHNbqHtkzzYtIwuSrJbKWXdZrHtbs3YUklYAIDl9cokb0vy81LKdc3YEUmOS3JmKeWQJLcn2b85dn6S1yWZk+TXSQ5OklrrglLKMUmubs47uta6YKwbK1gAoONW1pNua60/zOjrT5Jkl1HOr0kOW8rPOinJSct7bwULAHTcsrYjrwqsYQEAWk/CAgAdN567hNpKwQIAHefLDwEAWkDCAgAdt7J2CQ2SggUAOs4uIQCAFpCwAEDHaQkBAK1nlxAAQAtIWACg44Z7sOhWwQIAHbfqlytaQgBAB0hYAKDj7BICAFqvDwWLlhAA0HoSFgDouD48ml/BAgAdpyUEANACEhYA6Lg+PJpfwQIAHdeHNSxaQgBA60lYAKDj+rDoVsECAB2nJQQA0AISFgDoOC0hAKD1+rCtWUsIAGg9CQsAdNxwDxbdKlgAoOO0hAAAWkDCAgAdpyUEALSelhAAQAtIWACg47SEAIDW0xICAGgBCQsAdJyWEADQelpCAAAtIGEBgI6rdXjQU1jhFCwA0HHDWkIAAIMnYQGAjqt2CQEAbaclBADQAhIWAOg4LSEAoPX68KRbLSEAoPUkLADQcX14NL+CBQA6zhoWAKD1bGsGAGgBCQsAdJyWEADQerY1AwC0gIQFADpOSwgAaD27hAAAWkDCAgAdpyUEALSeXUIAAC0gYQGAjvPlhwBA62kJAQC0gIQFADrOLiEAoPX6sIZFSwgAaD0JCwB0nJYQANB6fShYtIQAgNaTsABAx636+UpS+hAj8T9XSplWa50+6HlA3/i7B0+mJcSyTBv0BKCn/N2DERQsAEDrKVgAgNZTsLAseugwGP7uwQgW3QIArSdhAQBaT8HCqEope5RSbi6lzCmlHD7o+UBflFJOKqXcU0r5xaDnAm2iYOEpSikTk5yYZM8k2yR5cyllm8HOCnrjG0n2GPQkoG0ULIxmuyRzaq231FofSzIzyd4DnhP0Qq31iiQLBj0PaBsFC6OZmuSOEZ/nNmMAMBAKFkZTRhmznQyAgVGwMJq5STYZ8XnjJPMGNBcAULAwqquTbFVK2byUsnqSA5LMGvCcAOgxBQtPUWt9PMm7k1yU5KYkZ9ZabxjsrKAfSilnJPlxkueVUuaWUg4Z9JygDTzpFgBoPQkLANB6ChYAoPUULABA6ylYAIDWU7AAAK2nYAEAWk/BAgC0noIFAGi9/w+aorV/Ci2RRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### plot confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "\n",
    "df_cm = pd.DataFrame(confusion_matrix(test_label, X_reduce_test['label']))\n",
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(df_cm, annot=True, fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7621316813597013"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_cm.iloc[0,0]+df_cm.iloc[1,1])/(np.sum(df_cm)[0]+np.sum(df_cm)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.87      0.86      0.86     11091\n",
      "         1.0       0.04      0.04      0.04      1500\n",
      "\n",
      "   micro avg       0.76      0.76      0.76     12591\n",
      "   macro avg       0.45      0.45      0.45     12591\n",
      "weighted avg       0.77      0.76      0.77     12591\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_label, X_reduce_test['label']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
